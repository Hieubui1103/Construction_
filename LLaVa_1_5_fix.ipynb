{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Hieubui1103/Construction_/blob/main/LLaVa_1_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "faj9CyxWiNtf",
    "outputId": "62acabd0-10c4-405a-af61-19d2dd62bda6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flash_attn\n",
      "  Downloading flash_attn-2.7.4.post1.tar.gz (6.0 MB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/6.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/6.0 MB\u001b[0m \u001b[31m107.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m124.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from flash_attn) (2.5.1+cu124)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from flash_attn) (0.8.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn) (2024.10.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->flash_attn)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->flash_attn)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->flash_attn)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->flash_attn)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->flash_attn)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->flash_attn)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->flash_attn)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->flash_attn)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->flash_attn)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->flash_attn)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->flash_attn) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->flash_attn) (3.0.2)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m115.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: flash_attn\n",
      "  Building wheel for flash_attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for flash_attn: filename=flash_attn-2.7.4.post1-cp311-cp311-linux_x86_64.whl size=187815463 sha256=d944fc7d2f962bce83fc4708c2fc0c21eaf8255962a0b350ae919362a51b7ef2\n",
      "  Stored in directory: /root/.cache/pip/wheels/3d/88/d8/284b89f56af7d5bf366b10d6b8e251ac8a7c7bf3f04203fb4f\n",
      "Successfully built flash_attn\n",
      "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, flash_attn\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed flash_attn-2.7.4.post1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
     ]
    }
   ],
   "source": [
    "pip install flash_attn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 705,
     "referenced_widgets": [
      "4b11e730544d492998cfce3d35da1adf",
      "7539a99c712e40d3b910f4b6a5e8ce0a",
      "348101dd49954d579a79bed1a046dac6",
      "c194bfee65c74a8c91ae40b0a0e2a562",
      "63f86504fdd64359914925b6978d403a",
      "36f6d0bbc89f4e2ba30a70492b38b21e",
      "c0feded10a16408387818665844d426a",
      "1f5e9ae5505a46ba9b1383a5eb7ad699",
      "a15415dc490e4a9bbc72d41bea0fa83c",
      "02233205eaf340aeaec498e85d5ff529",
      "175b91d50610477faafc908811ad6c38",
      "136cadbd1aae4c3faae957d896e80184",
      "c8c6482341034140a8edff10efda3253",
      "9424527dee614dceb3fe63e082a2f9dd",
      "0bebeb577b6b4edab6813b0c575a068d",
      "b4cd34c6f3d94f27942c2d347c77b1ff",
      "a772435d93c24306a6fbdac27ba77355",
      "82981f8f51b9465fb1e54aa5dd5716f9",
      "e8895118135b4c90bb5dadf9ac6f5e54",
      "9b5ca69f0a5749c9911979703e08e787",
      "f827c2b9741f40098c5e689e39518891",
      "9344471f620440338e1cb7ceec30c9da",
      "3b9165702fdf47798e9339db392a165c",
      "96510c780e8c4bdeb386f1d008b9d978",
      "eed4e35954dc4a918e76d5342bdce9cb",
      "cb749b5c867b4377ab934b66bbf75aab",
      "f4ebbf1ac53f4a5194fd44837252cef9",
      "14e0c9b3b3b64825bd8b86d1a6d2585e",
      "582862467af942d5af86a331829fb164",
      "27292fb854bc45b09e5b5119d0fe169d",
      "34267daa70544409be8f8dce669d2fa4",
      "e6cf7c1890834a98b1cff0c62f36b006",
      "b07984e805304104ba0c1f24de0022e4",
      "e99c83e214f3456a9cac6eda467201cf",
      "face100bfcc24917bb0d40c9b551bd88",
      "2a149bea0f4c4ab18278ca8fe82ba372",
      "2a3393b5f20b4fcf91513689ff9e93f5",
      "4b5a70c6a12f4c1eb5897432a0c38c55",
      "7c5a27277d4e4fa9b9c8bcfe16e1c66b",
      "2ad072fa7fec464ba2b66e9ea9617221",
      "628083c08be34629a51c65001ddbefca",
      "33336346ad2b4e14b97a775f9a868fe4",
      "673956cd1c4744928fc0c4252727bee3",
      "fc295f99c5874692a33278767fd92a6b",
      "69408df4e26f4f1a959c4887552d45d7",
      "b290082da12642f1813ba0bde04f79ed",
      "30ba8c33d7994e3e9f9abcb5e2ca2840",
      "187d60ea7c014fd981a3c2829113088b",
      "90c2394df87a4bed955be76eff9203b0",
      "b7daf2ecbe844f54bf6100d16bf63220",
      "5914afbcad8f4df6a893aa619941eeb6",
      "26efd1cb04094cb2876da44d87957f3e",
      "b8f9d5a3429b438ea25ef35070e5aa8d",
      "20944b0a46aa4e5bbff3186faaf2b0b7",
      "609ae67fcce94534bb743c3022765b80",
      "78504fa48ba34ac689327db14f2f8775",
      "0506e2aa3984411c8e13b234d464ab99",
      "84b946b53cd148f8b441b3a16a2580cb",
      "3942c34a9ada489a8b20fda131280fc2",
      "502c1ccdbe3d4b6fbe7fcd32d4463cfc",
      "e140b3a8c56947198cef710b867a0bea",
      "842c5e32171a469184945404b6d30d9a",
      "2ef0a23d7e2c40eabdeadfd136cb4ece",
      "febc7742d8e84a9a9ebe7a8de0c85eb0",
      "523dd27dbc9a4ddb96806bab47d388f4",
      "ed7d3176f624494e8f49fe100d339675",
      "9647810b062a44759e7c6aeacdf6fdef",
      "854b528a05a54fd380f2d26d0e086a10",
      "e90a941f67534cb4b278f788941adb2d",
      "4d49d2e344ca423e87dfde1ad72d49e7",
      "0d8a5a92596840b5912b0afbbcd93082",
      "97bd5791e08d4735809e48fb0184973f",
      "cad2216287fe44218c821dc31887d147",
      "c8c41769ee664a5ea01ea3c26cb56d42",
      "0856080af5ae4fa88431059e5d182789",
      "61d1cfa7e55f4aa1a1de220239863409",
      "e37206fedc2a42c2bc8586bca72322db",
      "cef90c2ca5354907bd38a9c57028b263",
      "bb517186b3e6447681e0d85d801f4b8b",
      "2a5e441d0a174ee081f9595cf8175700",
      "6c2a734703be4570a911633fee6d29ac",
      "aba8ec4c3a4b4fd897dd34bf1e6672a6",
      "b299ee19b54b4675ae7ff2e437b3de3c",
      "9a80513d061940d4b48782d15b6e59ad",
      "80dfc897a3994f939265f2778f850940",
      "473e929e10344f86aea569791f0f0eb2",
      "ab38b21f0fbb43d5acd474e91213a7a2",
      "5e26f667ee054280843a13e5979f32d6",
      "e1ddc423e4db46408cfaae0f4b4d514d",
      "48c0d2cc1dcb4377ac6a59d91fbc3bf0",
      "387ecb0a59124168a79e2a7fe4333c43",
      "6db58b368c2d40d280f88b75c8efe37c",
      "13f84e1602064a98abfd30e6c0e51262",
      "fcd6759a3eda4587a334cc2657efba26",
      "9e4ed9feafb54218a62e981eb08d7f2c",
      "170014010cd8463a965f7c8e022c166e",
      "ffb9fc627eee463f815350a93919b6b3",
      "2d91853e9b684dfcacd7b6b37451e705",
      "99d6c0879e6a48a0a5a427742b3856f0",
      "d9aee68f53894d209b204fc38bd904ba",
      "dc7088a0d8ea437194dfe072fec9b833",
      "93e899b4c8674513b7e9fca373008335",
      "c11120cea5934a7a8db37326eecc1825",
      "fe323b9751ed43c28588b090ff5ce2dd",
      "7c62f16b3578493bad968c1d804b2988",
      "141022fbc4e7446dabb5407c4e0b647a",
      "2d6988d0130b42ecaeeff910a31dc497",
      "c3f75086ba7e410187b4535db9b6ab52",
      "c2e389018be94496a1def733c32ca7d7",
      "daaad6c6b1104f09a680a9085ccb18d8",
      "9590a2c3ecd34ba183c7770d80fa44de",
      "589d278cc14841a68b3464f2ed020e38",
      "b9ac4157734e4ac280888903783c727a",
      "91b338b4a5584736842e0614fd010aa8",
      "19858d336ff4427599fc11abe0b3b977",
      "811a2b9b13104d7da75ec8ddae252627",
      "2c7084a2aef64d3c9f9f9bee51c6e6c7",
      "783c7c9ac8ee492294ca93bed3821d8f",
      "464db4bbf2534aebb631c904ac4dd925",
      "c7c09d07cf1e44af8f290acaad0c18fa",
      "6ec50e421fac4368b5bee3b0fc0939f3",
      "42f18952455d4f14aa306cbf383c6a05",
      "222ed46aac91404da1e93c20c40298b1",
      "02cf1e95d9e34937b3708fa73cbd3c85",
      "e58e51fcb1f9455683fc736d546011f9",
      "e87a1c40ee6f4ce69b87b5c21427dea6",
      "24a3177419954a7282202f8863cdb191",
      "a29933177ec14b56906b61b90c8dc8c0",
      "4bd67838e904462cace2032fe8912d0d",
      "747f4b44647948bdbe0dd9995312e283",
      "2ab29095b8c84b539d493413bd479dfc",
      "ff78a1bb5aa44d0aba73a2d59d259307",
      "42b4cb4298384426953efef80616299e",
      "9ad2022258ad4809bdfc559aa4f77d5b",
      "8244246b32894d1e943d42607c1bf02f",
      "7e4571e5eb06416f9827e50ae82e4b3a",
      "cdc7c22dcfd945c490f8a1388c8ce665",
      "f5b6aaea084347e8aac0a9bcf6c3abca",
      "f98c8aa9523240959ce15e91647b7bce",
      "4ede2ba2f1bd4cae9720e421daa49712",
      "63d81049376b40a2a1c638d659c17260",
      "9febb7bd31784e309def55154bd2ab2f",
      "d19ca2f84c0f4b3689aa598aabe0c54a",
      "1f0547c0da5742888b34f8ff3bc29778",
      "ccce63cd502247079a1cbc6a639e4de7",
      "bd06eea6669d4b37bea0a31ae95d6473",
      "5570de3b41bd40bdb721427181c66cec",
      "3027f1d79b5645eaa7b271e40415224e",
      "272ebe6b00c14d96828e9be7ee23b88b",
      "0d67fd761e7c4213b3d5fb3e28199601",
      "a598d4fa6bc94001a8b805c756e11239",
      "6d35b711ad9f47fcba3b646fbe28eb29",
      "f378eea70b844560bf78d1c3f85e7cbc",
      "6342dba7ea824294869a422dfbe7c776",
      "ae9da5b2c33e48189e09767bc55a6186",
      "a30b7def0c16464f9c23b4a8e7a3bc82",
      "00c851985f24449aab0b2d98f6e5e526",
      "355e923e646f4b7393f8149f567936a7",
      "2842e2160f9f40c49e0b03d436df22cf",
      "a363c3c0a5394d61a528e0f911e3359a",
      "186fad59530c456f9d334ef084f9e85b",
      "3ff6798f2f3e42abb60ec03bfa03f677",
      "4e658b7e7f1442d9a531d409968aafc1",
      "1264a58771a9450b8db34c5353f28583",
      "2b8e797922d74756afc178764943394a",
      "43597580f4cc4684b86513c5fd3b8fb4",
      "05064d9c4f1b41c991e1b35ea2c9423e",
      "a6ea081578ac4b51924fd409a49a6719",
      "77cefe4c5a7c49c7a0c2b3b6f867e1be",
      "c654b0a581c544af8292e0c64cffdad5",
      "2ddd805e3cd64e99b154e94e0de1c52b",
      "eb44159cd7b04e34b3a8fb55d0cf5a33",
      "93d3fb3838c04e4f88a7fc3ffc629d53",
      "b2ed23d3e16e4cd8bfdf046e667d56fb",
      "c146c9d93b5d4c279716f01aadd7ba01",
      "68ad58602d5c45d791a1874887439b93"
     ]
    },
    "id": "t_L-WfgxMuiO",
    "outputId": "c6f26d7d-5695-49be-b3db-3229077c0bca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b11e730544d492998cfce3d35da1adf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/950 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "136cadbd1aae4c3faae957d896e80184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/70.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b9165702fdf47798e9339db392a165c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e99c83e214f3456a9cac6eda467201cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69408df4e26f4f1a959c4887552d45d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78504fa48ba34ac689327db14f2f8775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.18G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model was loaded with use_flash_attention_2=True, which is deprecated and may be removed in a future release. Please use `attn_implementation=\"flash_attention_2\"` instead.\n",
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9647810b062a44759e7c6aeacdf6fdef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cef90c2ca5354907bd38a9c57028b263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/141 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1ddc423e4db46408cfaae0f4b4d514d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "processor_config.json:   0%|          | 0.00/173 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9aee68f53894d209b204fc38bd904ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.json:   0%|          | 0.00/701 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9590a2c3ecd34ba183c7770d80fa44de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/505 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42f18952455d4f14aa306cbf383c6a05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.45k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42b4cb4298384426953efef80616299e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f0547c0da5742888b34f8ff3bc29778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/3.62M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae9da5b2c33e48189e09767bc55a6186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/41.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43597580f4cc4684b86513c5fd3b8fb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/552 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from transformers import AutoProcessor, LlavaForConditionalGeneration\n",
    "\n",
    "model_id = \"llava-hf/llava-1.5-7b-hf\"\n",
    "model = LlavaForConditionalGeneration.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    low_cpu_mem_usage=True,\n",
    "    use_flash_attention_2=True\n",
    ").to(0)\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "# Define a chat histiry and use `apply_chat_template` to get correctly formatted prompt\n",
    "# Each value in \"content\" has to be a list of dicts with types (\"text\", \"image\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2m7C29u4MUql",
    "outputId": "d1b47db4-f648-4752-dd3a-3492c2a4481c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['images/image001.jpg', 'images/image002.jpg', 'images/image003.jpg', 'images/image004.jpg', 'images/image005.jpg', 'images/image006.jpg', 'images/image007.jpg', 'images/image008.jpg', 'images/image009.jpg', 'images/image010.jpg', 'images/image011.jpg', 'images/image012.jpg', 'images/image013.jpg', 'images/image014.jpg', 'images/image015.jpg', 'images/image016.jpg', 'images/image017.jpg', 'images/image018.jpg', 'images/image019.jpg', 'images/image020.jpg', 'images/image021.jpg', 'images/image022.jpg', 'images/image023.jpg', 'images/image024.jpg', 'images/image025.jpg', 'images/image026.jpg', 'images/image027.jpg', 'images/image028.jpg', 'images/image029.jpg', 'images/image030.jpg', 'images/image031.jpg', 'images/image032.jpg', 'images/image033.jpg', 'images/image034.jpg', 'images/image035.jpg', 'images/image036.jpg', 'images/image037.jpg', 'images/image038.jpg', 'images/image039.jpg', 'images/image040.jpg', 'images/image041.jpg', 'images/image042.jpg', 'images/image043.jpg', 'images/image044.jpg', 'images/image045.jpg', 'images/image046.jpg', 'images/image047.jpg', 'images/image048.jpg', 'images/image049.jpg', 'images/image050.jpg', 'images/image051.jpg', 'images/image052.jpg', 'images/image053.jpg', 'images/image054.jpg', 'images/image055.jpg', 'images/image056.jpg', 'images/image057.jpg', 'images/image058.jpg', 'images/image059.jpg', 'images/image060.jpg', 'images/image061.jpg', 'images/image062.jpg', 'images/image063.jpg', 'images/image064.jpg', 'images/image065.jpg', 'images/image066.jpg', 'images/image067.jpg', 'images/image068.jpg', 'images/image069.jpg', 'images/image070.jpg', 'images/image071.jpg', 'images/image072.jpg', 'images/image073.jpg', 'images/image074.jpg', 'images/image075.jpg', 'images/image076.jpg', 'images/image077.jpg', 'images/image078.jpg', 'images/image079.jpg', 'images/image080.jpg', 'images/image081.jpg', 'images/image082.jpg', 'images/image083.jpg', 'images/image084.jpg', 'images/image085.jpg', 'images/image086.jpg', 'images/image087.jpg', 'images/image088.jpg', 'images/image089.jpg', 'images/image090.jpg', 'images/image091.jpg', 'images/image092.jpg', 'images/image093.jpg', 'images/image094.jpg', 'images/image095.jpg', 'images/image096.jpg', 'images/image097.jpg', 'images/image098.jpg', 'images/image099.jpg', 'images/image100.jpg', 'images/image101.jpg', 'images/image102.jpg', 'images/image103.jpg', 'images/image104.jpg']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the directory\n",
    "image_dir = \"images/\"\n",
    "\n",
    "# Get all files in the directory and sort them\n",
    "image_files = sorted(\n",
    "    [os.path.join(image_dir, file) for file in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, file))],\n",
    "    key=lambda x: int(''.join(filter(str.isdigit, os.path.basename(x)))) if any(c.isdigit() for c in os.path.basename(x)) else x\n",
    ")\n",
    "\n",
    "print(image_files)  # Prints a sorted list of image file paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "43finkZnRM4V",
    "outputId": "837a69de-32ee-45c8-d54d-c0bbec3520e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response_obj_LLaVa.json created successfully!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "# Define the JSON file name\n",
    "json_filename = \"response_obj_LLaVa.json\"\n",
    "\n",
    "# Create an empty JSON structure\n",
    "data = {}\n",
    "\n",
    "# Write the empty structure to the file\n",
    "with open(json_filename, \"w\") as file:\n",
    "    json.dump(data, file, indent=4)\n",
    "\n",
    "print(f\"{json_filename} created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "euGaSen2Rt1f"
   },
   "outputs": [],
   "source": [
    "def save_data(data_dict, data,image):\n",
    "    print(image)\n",
    "    data_dict[image] = data\n",
    "    with open(json_filename, \"w\") as file:\n",
    "        json.dump(data_dict, file, indent=4)\n",
    "\n",
    "    print(f\"Response saved in {json_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "78UdBUSwMGbW"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vJjBxHOxRqAi",
    "outputId": "214b135b-3fb7-444c-da65-0f458efb7e70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ER:  \n",
      " What objects from the list: ['Hardhat', 'Mask', 'NO-Hardhat', 'NO-Mask', 'NO-Safety Vest', 'Person', 'Safety Cone', 'Safety Vest', 'Vehicle', 'machinery'] do you see in this photo? ASSISTANT: In the photo, there are two people wearing hardhats, which are safety helmets. Additionally, there is a safety cone present in the scene. The other objects from the list, such as a mask, a no-hardhat sign, a no-mask sign, a no-safety vest sign, a vehicle, and machinery, are not visible in the image.\n"
     ]
    }
   ],
   "source": [
    "jobs = [\"Hardhat\", \"Mask\", \"NO-Hardhat\", \"NO-Mask\", \"NO-Safety Vest\", \"Person\", \"Safety Cone\",\"Safety Vest\", \"Vehicle\", \"machinery\"]\n",
    "\n",
    "Question_1 = f\"\"\" The possible object categories in this dataset are:\n",
    "              {jobs}. Which of these objects appear in the image? Answer with only the object names from the list.\n",
    "              Explain your answer as well.\"\"\"\n",
    "Question_2 = f\"\"\" What objects from the list: {jobs} do you see in this photo?\"\"\"\n",
    "conversation = [\n",
    "        {\n",
    "\n",
    "          \"role\": \"user\",\n",
    "          \"content\": [\n",
    "              {\"type\": \"text\", \"text\": Question_2},\n",
    "              {\"type\": \"image\"},\n",
    "            ],\n",
    "        },\n",
    "]\n",
    "prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)\n",
    "\n",
    "raw_image = Image.open(\"images/image020.jpg\")\n",
    "inputs = processor(images=raw_image, text=prompt, return_tensors='pt').to(0, torch.float16)\n",
    "\n",
    "output = model.generate(**inputs, max_new_tokens=10000, do_sample=False)\n",
    "response_1 = processor.decode(output[0][2:], skip_special_tokens=True)\n",
    "print(response_1)\n",
    "del inputs, output, response_1\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "wMKJCCJSiMtp",
    "outputId": "03313e36-ebbb-48a9-ffd6-4b5af7ac1b36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Current process image: images/image001.jpg  \n",
      "\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "['Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes']\n",
      "images/image001.jpg\n",
      "Response saved in response_obj_LLaVa.json\n",
      "\n",
      " Current process image: images/image002.jpg  \n",
      "\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "['Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes']\n",
      "images/image002.jpg\n",
      "Response saved in response_obj_LLaVa.json\n",
      "\n",
      " Current process image: images/image003.jpg  \n",
      "\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "['Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes']\n",
      "images/image003.jpg\n",
      "Response saved in response_obj_LLaVa.json\n",
      "\n",
      " Current process image: images/image004.jpg  \n",
      "\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "['Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes']\n",
      "images/image004.jpg\n",
      "Response saved in response_obj_LLaVa.json\n",
      "\n",
      " Current process image: images/image005.jpg  \n",
      "\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "['Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes']\n",
      "images/image005.jpg\n",
      "Response saved in response_obj_LLaVa.json\n",
      "\n",
      " Current process image: images/image006.jpg  \n",
      "\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n",
      "ER:  \n",
      " Does this object/identification appear in this image? Only answer yes or no ASSISTANT: Yes\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-f73c55637c52>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraw_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mresponse_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2254\u001b[0m             \u001b[0;31m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2255\u001b[0;31m             result = self._sample(\n\u001b[0m\u001b[1;32m   2256\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2257\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3242\u001b[0m         \u001b[0mis_prefill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3243\u001b[0;31m         while self._has_unfinished_sequences(\n\u001b[0m\u001b[1;32m   3244\u001b[0m             \u001b[0mthis_peer_finished\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msynced_gpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3245\u001b[0m         ):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "jobs = [\"Hardhat\", \"Mask\", \"NO-Hardhat\", \"NO-Mask\", \"NO-Safety Vest\", \"Person\", \"Safety Cone\",\"Safety Vest\", \"Vehicle\", \"machinery\"]\n",
    "for image in image_files:\n",
    "  print(f\"\\n Current process image: {image}  \\n\")\n",
    "  answer_data_for_each = []\n",
    "  for job in jobs:\n",
    "    conversation = [\n",
    "        {\n",
    "\n",
    "          \"role\": \"user\",\n",
    "          \"content\": [\n",
    "              {\"type\": \"text\", \"text\": f\"\"\" Does this object/identification appear in this image? Only answer yes or no\"\"\"},\n",
    "              {\"type\": \"image\"},\n",
    "            ],\n",
    "        },\n",
    "    ]\n",
    "    prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)\n",
    "\n",
    "    raw_image = Image.open(image)\n",
    "    inputs = processor(images=raw_image, text=prompt, return_tensors='pt').to(0, torch.float16)\n",
    "\n",
    "    output = model.generate(**inputs, max_new_tokens=10000, do_sample=False)\n",
    "    response_1 = processor.decode(output[0][2:], skip_special_tokens=True)\n",
    "\n",
    "    match = re.search(r\"ASSISTANT:\\s*(\\w+)\", response_1)\n",
    "    if match:\n",
    "        answer = match.group(1)\n",
    "        answer_data_for_each.append(answer)\n",
    "    else:\n",
    "        print(\"No match found.\")\n",
    "    print(response_1)\n",
    "\n",
    "    # Clear cache\n",
    "    del inputs, output, response_1, match\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "  print(answer_data_for_each)\n",
    "  save_data(data, answer_data_for_each,image)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyN1r/CLGul9SrwYSVjNjUeL",
   "gpuType": "L4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
