{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOnv8GSiDhoeO94E0E4G+w5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hieubui1103/Construction_/blob/main/Florence.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoProcessor, AutoModelForCausalLM\n",
        "from PIL import Image\n",
        "import requests\n",
        "import copy\n",
        "import torch\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "4vltKXolSdY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = 'microsoft/Florence-2-large-ft'\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, trust_remote_code=True, torch_dtype='auto').eval().cuda()\n",
        "processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True)"
      ],
      "metadata": {
        "id": "yZKwsBInSwSH",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!mkdir temp_clone\n",
        "%cd temp_clone\n",
        "\n",
        "# Sparse-checkout from here\n",
        "!git clone --filter=blob:none --no-checkout https://github.com/Hieubui1103/Construction_.git\n",
        "%cd Construction_\n",
        "!git sparse-checkout init --cone\n",
        "!git sparse-checkout set Images\n",
        "!git checkout main\n",
        "\n",
        "# get back to the main directory\n",
        "%cd ../../"
      ],
      "metadata": {
        "id": "MO07POSDsP3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import re\n",
        "\n",
        "\n",
        "# Path to the folder containing 1000 images\n",
        "image_folder_action = \"temp_clone/Construction_/Images/Action_cons_files\"\n",
        "output_folder_action = \"images_action\"\n",
        "\n",
        "image_folder_emotion = \"temp_clone/Construction_/Images/Emotion_cons_files\"\n",
        "output_folder_emotion = \"images_emotion\"\n",
        "\n",
        "# Create output folders if they don't exist\n",
        "os.makedirs(output_folder_action, exist_ok=True)\n",
        "os.makedirs(output_folder_emotion, exist_ok=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "6OAQVRm2-Hwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_batches(image_folder, output_folder):\n",
        "    \"\"\"\n",
        "    Create 5 batches of images from the specified folder and copy them into separate folders.\n",
        "    \"\"\"\n",
        "    # Create 5 batch folders\n",
        "    batch_size = 200\n",
        "    for batch_num in range(1, 6):\n",
        "        batch_folder = os.path.join(output_folder, f\"batch_{batch_num}\")\n",
        "        os.makedirs(batch_folder, exist_ok=True)\n",
        "\n",
        "    # Get all image files and sort them numerically\n",
        "    image_files = sorted([f for f in os.listdir(image_folder) if f.lower().endswith(('.jpg', '.png', '.jpeg'))])\n",
        "\n",
        "    def extract_number(filename):\n",
        "        match = re.search(r'\\d+', filename)\n",
        "        return int(match.group()) if match else -1\n",
        "\n",
        "    image_files.sort(key=extract_number)\n",
        "\n",
        "    # Distribute images into batches\n",
        "    for i, file in enumerate(image_files):\n",
        "        batch_num = (i // batch_size) + 1\n",
        "        if batch_num > 5:  # Ensure no more than 5 batches\n",
        "            break\n",
        "        source_path = os.path.join(image_folder, file)\n",
        "        destination_path = os.path.join(output_folder, f\"batch_{batch_num}\", file)\n",
        "        shutil.copy(source_path, destination_path)\n",
        "\n",
        "    print(\"Images have been copied into 5 batches.\")\n",
        "\n",
        "\n",
        "# Create batches for action images\n",
        "create_batches(image_folder_action, output_folder_action)\n",
        "\n",
        "# Create batches for emotion images\n",
        "create_batches(image_folder_emotion, output_folder_emotion)"
      ],
      "metadata": {
        "id": "62g_tz2f_rTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the directory\n",
        "image_dir_batch1 = \"images_action/batch_1\"\n",
        "image_dir_batch2 = \"images_action/batch_2\"\n",
        "image_dir_batch3 = \"images_action/batch_3\"\n",
        "image_dir_batch4 = \"images_action/batch_4\"\n",
        "image_dir_batch5 = \"images_action/batch_5\"\n",
        "\n",
        "# Get all files in the directory and sort them\n",
        "def get_sorted_files(image_dir):\n",
        "  image_files = sorted(\n",
        "      [os.path.join(image_dir, file) for file in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, file))],\n",
        "      key=lambda x: int(''.join(filter(str.isdigit, os.path.basename(x)))) if any(c.isdigit() for c in os.path.basename(x)) else x\n",
        "  )\n",
        "  return image_files\n",
        "\n",
        "print(get_sorted_files(image_dir_batch3))  # Prints a sorted list of image file paths\n"
      ],
      "metadata": {
        "id": "xkPfipRhS5Ma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the directory\n",
        "emotion_dir_batch1 = \"images_emotion/batch_1\"\n",
        "emotion_dir_batch2 = \"images_emotion/batch_2\"\n",
        "emotion_dir_batch3 = \"images_emotion/batch_3\"\n",
        "emotion_dir_batch4 = \"images_emotion/batch_4\"\n",
        "emotion_dir_batch5 = \"images_emotion/batch_5\"\n",
        "\n",
        "print(get_sorted_files(emotion_dir_batch3))  # Prints a sorted list of image file paths\n"
      ],
      "metadata": {
        "id": "_cZTSzBfS6Ea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_example(task_prompt, image, text_input=None):\n",
        "    if text_input is None:\n",
        "        prompt = task_prompt\n",
        "    else:\n",
        "        prompt = task_prompt + text_input\n",
        "    inputs = processor(text=prompt, images=image, return_tensors=\"pt\").to('cuda', torch.float16)\n",
        "    generated_ids = model.generate(\n",
        "      input_ids=inputs[\"input_ids\"].cuda(),\n",
        "      pixel_values=inputs[\"pixel_values\"].cuda(),\n",
        "      max_new_tokens=1024,\n",
        "      early_stopping=False,\n",
        "      do_sample=False,\n",
        "      num_beams=3,\n",
        "    )\n",
        "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n",
        "    parsed_answer = processor.post_process_generation(\n",
        "        generated_text,\n",
        "        task=task_prompt,\n",
        "        image_size=(image.width, image.height)\n",
        "    )\n",
        "\n",
        "    return parsed_answer\n",
        "\n"
      ],
      "metadata": {
        "id": "sJ_V-veES034"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "# Define the JSON file name\n",
        "#json_filename = \"response_Flo_action_1.json\"\n",
        "\n",
        "for i in range(1, 6):\n",
        "  json_filename_action = f\"response_action_LLaVa_{i}.json\"\n",
        "  json_filename_emotion = f\"response_emotion_LLaVa_{i}.json\"\n",
        "  # Create an empty JSON structure\n",
        "  data = {}\n",
        "\n",
        "  # Write the empty structure to the file\n",
        "  with open(json_filename_action, \"w\") as file:\n",
        "      json.dump(data, file, indent=4)\n",
        "  with open(json_filename_emotion, \"w\") as file:\n",
        "      json.dump(data, file, indent=4)\n",
        "\n",
        "  print(f\"{json_filename_action} created successfully!\")\n",
        "  print(f\"{json_filename_emotion} created successfully!\")"
      ],
      "metadata": {
        "id": "KhWGERzLf14-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer retrieval with direct questioning\n"
      ],
      "metadata": {
        "id": "W8yNnDZeBm0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# action classes\n",
        "jobs = [\n",
        "        \"Operating heavy machinery\",\n",
        "                    \"Lifting materials\",\n",
        "                    \"Measuring and marking surfaces\",\n",
        "                    \"Mixing cement\",\n",
        "                    \"Collaborating in teams\",\n",
        "                    \"Using hand tools\",\n",
        "                    \"Inspecting completed work\",\n",
        "                    \"Communicating with supervisors\",\n",
        "                    \"Following safety protocols\",\n",
        "                    \"Taking breaks/resting\"\n",
        "        ]\n",
        "\n",
        "# emotion classes\n",
        "emotions = [\n",
        "        \"Focused\",\n",
        "        \"Determined\",\n",
        "        \"Tired\",\n",
        "        \"Alert\",\n",
        "        \"Satisfied\",\n",
        "        \"Anxious\",\n",
        "        \"Proud\",\n",
        "        \"Frustrated\",\n",
        "        \"Cooperative\",\n",
        "        \"Relieved\"\n",
        "        ]\n",
        "\n",
        "# data retrieval\n",
        "def image_process(image_dir, json_filename, category):\n",
        "  image_files = get_sorted_files(image_dir)\n",
        "  data = {}\n",
        "  for raw_image in image_files:\n",
        "      print(f\"\\n Current process image: {raw_image}  \\n\")\n",
        "      image = Image.open(raw_image)\n",
        "      answer_data_for_each = []\n",
        "      for j in category[1]:\n",
        "        task_prompt = f'Does this {category[0]} of \"{j}\" appear in the photo? Answer only \"yes\" or \"no\". Do not explain or add any other words.\"'\n",
        "        results = run_example(task_prompt, image=image)\n",
        "        response_text = list(results.values())[0]\n",
        "        answer_data_for_each.append(response_text)\n",
        "\n",
        "        print(results)\n",
        "\n",
        "        del results, response_text\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "      print(answer_data_for_each)\n",
        "\n",
        "      data[raw_image] = answer_data_for_each\n",
        "      with open(json_filename, \"w\") as file:\n",
        "          json.dump(data, file, indent=4)\n",
        "\n",
        "      del answer_data_for_each\n",
        "\n",
        "  del data\n",
        "  torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "jCILRJh5jYvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get data for action recognition**\n"
      ],
      "metadata": {
        "id": "o5blYM6oURiF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_process(image_dir = image_dir_batch1, json_filename=\"response_Flo_action_1.json\", category=[\"action\",jobs])"
      ],
      "metadata": {
        "id": "EnWNhlj0S-Zv",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_process(image_dir = image_dir_batch2, json_filename=\"response_Flo_action_2.json\", category=[\"action\",jobs])"
      ],
      "metadata": {
        "collapsed": true,
        "id": "XFISoFGKVSBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_process(image_dir=image_dir_batch3, json_filename=\"response_Flo_action_3.json\", category=[\"action\",jobs])"
      ],
      "metadata": {
        "collapsed": true,
        "id": "tWsS3C_KYYj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_process(image_dir=image_dir_batch4, json_filename=\"response_Flo_action_4.json\", category=[\"action\",jobs])"
      ],
      "metadata": {
        "collapsed": true,
        "id": "eicTutM4YkEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_process(image_dir=image_dir_batch5, json_filename=\"response_Flo_action_5.json\", category=[\"action\",jobs])"
      ],
      "metadata": {
        "collapsed": true,
        "id": "C6Le9uShYknZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get data for emotion recognition**"
      ],
      "metadata": {
        "id": "m8NZ0v9cVf5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_process(image_dir = emotion_dir_batch1, json_filename=\"response_Flo_emotion_1.json\", category=[\"emotion\",emotions])"
      ],
      "metadata": {
        "collapsed": true,
        "id": "qY7gYgyAVrC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_process(image_dir = emotion_dir_batch2, json_filename=\"response_Flo_emotion_2.json\", category=[\"emotion\",emotions])"
      ],
      "metadata": {
        "collapsed": true,
        "id": "MS-3_qV0ZoR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_process(image_dir=emotion_dir_batch3, json_filename=\"response_Flo_emotion_3.json\", category=[\"emotion\",emotions])"
      ],
      "metadata": {
        "collapsed": true,
        "id": "9MA3unyAcjNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_process(image_dir=emotion_dir_batch4, json_filename=\"response_Flo_emotion_4.json\", category=[\"emotion\",emotions])"
      ],
      "metadata": {
        "collapsed": true,
        "id": "jnDwX1zAha-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_process(image_dir=emotion_dir_batch5, json_filename=\"response_Flo_emotion_5.json\", category=[\"emotion\",emotions])"
      ],
      "metadata": {
        "collapsed": true,
        "id": "kCecONgWkUWK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}